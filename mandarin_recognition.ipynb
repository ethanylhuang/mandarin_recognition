{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f983d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import os\n",
    "import sys\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ba52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory\n",
    "os.chdir(r'C:\\Users\\ethan\\Desktop\\mandarin_recognition_code2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac5b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_chinese = os.listdir(train_dir)\\ntest_chinese = os.listdir(test_dir)\\nlen(train_chinese)\\nlen(test_chinese)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dir = pathlib.Path(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Train\\Train')\n",
    "test_dir = pathlib.Path(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Test\\Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f558217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3223042 files belonging to 7330 classes.\n",
      "Using 2578434 files for training.\n",
      "Using 644608 files for validation.\n",
      "Found 776523 files belonging to 7330 classes.\n"
     ]
    }
   ],
   "source": [
    "#make tensorflow dataset from image directory (if not already saved on local disk)\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    image_size = (56, 56),\n",
    "    shuffle = True,\n",
    "    seed=42,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'both',\n",
    "    interpolation = \"bilinear\",\n",
    "    crop_to_aspect_ratio = False\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    image_size = (56, 56),\n",
    "    shuffle = True,\n",
    "    interpolation = \"bilinear\",\n",
    "    crop_to_aspect_ratio = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if it is first time generating dataset, save it to local disk\n",
    "tf.data.Dataset.save(train_dataset, 'train_dataset')\n",
    "tf.data.Dataset.save(val_dataset, 'val_dataset')\n",
    "tf.data.Dataset.save(test_dataset, 'test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c416e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset from local disk\n",
    "train_dataset = tf.data.Dataset.load('train_dataset')\n",
    "test_dataset = tf.data.Dataset.load('test_dataset')\n",
    "val_dataset = tf.data.Dataset.load('val_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e47aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (32, 56, 56, 1)\n",
      "Labels shape: (32, 7330)\n"
     ]
    }
   ],
   "source": [
    "#Check shape of dataset\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972eeea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting rescaling\n"
     ]
    }
   ],
   "source": [
    "print(\"starting rescaling\")\n",
    "\n",
    "rescaling_layer = layers.Rescaling(scale=1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (rescaling_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e985e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting normalization\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[7], line 46\u001b[0m\n",
      "\u001b[0;32m     41\u001b[0m     overall_variance \u001b[38;5;241m=\u001b[39m variance_accumulator \u001b[38;5;241m/\u001b[39m sample_count\n",
      "\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overall_mean\u001b[38;5;241m.\u001b[39mnumpy(), overall_variance\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;32m---> 46\u001b[0m train_mean, train_variance \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_mean_variance_incrementally\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     47\u001b[0m test_mean, test_variance \u001b[38;5;241m=\u001b[39m calculate_mean_variance_incrementally(test_dataset)\n",
      "\u001b[0;32m     48\u001b[0m val_mean, val_variance \u001b[38;5;241m=\u001b[39m calculate_mean_variance_incrementally(val_dataset)\n",
      "\n",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m, in \u001b[0;36mcalculate_mean_variance_incrementally\u001b[1;34m(dataset)\u001b[0m\n",
      "\u001b[0;32m     19\u001b[0m variance_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[0;32m     20\u001b[0m sample_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m dataset:\n",
      "\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Flatten images to process all pixels\u001b[39;00m\n",
      "\u001b[0;32m     24\u001b[0m     flattened_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(images, (images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;32m     25\u001b[0m     batch_size, num_pixels \u001b[38;5;241m=\u001b[39m flattened_images\u001b[38;5;241m.\u001b[39mshape\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n",
      "\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n",
      "\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n",
      "\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n",
      "\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n",
      "\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3011\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n",
      "\u001b[0;32m   3009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n",
      "\u001b[0;32m   3010\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m-> 3011\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   3012\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3013\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   3014\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n",
      "\u001b[0;32m   3015\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"starting normalization\")\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "'''\n",
    "train_dataset_for_adapt = train_dataset.map(lambda x, y: x)\n",
    "test_dataset_for_adapt = test_dataset.map(lambda x, y: x)\n",
    "val_dataset_for_adapt = val_dataset.map(lambda x, y: x)\n",
    "\n",
    "normalization_layer_train = layers.Normalization(axis=-1)\n",
    "normalization_layer_test = layers.Normalization(axis=-1)\n",
    "normalization_layer_val = layers.Normalization(axis=-1)\n",
    "'''\n",
    "\n",
    "def calculate_mean_variance_incrementally(dataset):\n",
    "    # Initialize variables for mean, variance, and sample count\n",
    "    mean_accumulator = 0.0\n",
    "    variance_accumulator = 0.0\n",
    "    sample_count = 0\n",
    "    \n",
    "    for images, _ in dataset:\n",
    "        # Flatten images to process all pixels\n",
    "        flattened_images = tf.reshape(images, (images.shape[0], -1))\n",
    "        batch_size, num_pixels = flattened_images.shape\n",
    "        \n",
    "        # Update total sample count\n",
    "        sample_count += batch_size * num_pixels\n",
    "        \n",
    "        # Calculate batch mean and variance\n",
    "        batch_mean = tf.reduce_mean(flattened_images)\n",
    "        batch_variance = tf.reduce_mean(tf.square(flattened_images - batch_mean))\n",
    "        \n",
    "        # Incrementally update the accumulated mean and variance\n",
    "        delta = batch_mean - mean_accumulator\n",
    "        mean_accumulator += delta / sample_count * (batch_size * num_pixels)\n",
    "        variance_accumulator += batch_variance * (batch_size * num_pixels)\n",
    "    \n",
    "    # Finalize mean and variance calculation\n",
    "    overall_mean = mean_accumulator\n",
    "    overall_variance = variance_accumulator / sample_count\n",
    "    \n",
    "    return overall_mean.numpy(), overall_variance.numpy()\n",
    "\n",
    "\n",
    "train_mean, train_variance = calculate_mean_variance_incrementally(train_dataset)\n",
    "test_mean, test_variance = calculate_mean_variance_incrementally(test_dataset)\n",
    "val_mean, val_variance = calculate_mean_variance_incrementally(val_dataset)\n",
    "\n",
    "normalization_layer_train = layers.Normalization(axis=-1, mean=train_mean, variance=train_variance)\n",
    "normalization_layer_test = layers.Normalization(axis=-1, mean=test_mean, variance=test_variance)\n",
    "normalization_layer_val = layers.Normalization(axis=-1, mean=val_mean, variance=val_variance)\n",
    "\n",
    "'''\n",
    "print(\"starting adapt\")\n",
    "normalization_layer_train.adapt(train_dataset_for_adapt)\n",
    "normalization_layer_test.adapt(test_dataset_for_adapt)\n",
    "normalization_layer_val.adapt(val_dataset_for_adapt)\n",
    "\n",
    "print(\"finished adapt\")\n",
    "\n",
    "'''\n",
    "'''\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer_train(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer_test(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer_val(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1509d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting augmentation\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_39772\\3991776876.py\", line 8, in None  *\n        lambda x, y: (data_augmentation(x), y)\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\preprocessing\\image_preprocessing.py\", line 444, in call\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"random_flip_2\" \"                 f\"(type RandomFlip).\n    \n    Image augmentation layers are expecting inputs to be rank 3 (HWC) or 4D (NHWC) tensors. Got shape: (None, None, 56, 56, 1)\n    \n    Call arguments received by layer \"random_flip_2\" \"                 f\"(type RandomFlip):\n      • inputs=tf.Tensor(shape=(None, None, 56, 56, 1), dtype=float32)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting augmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m      3\u001b[0m data_augmentation \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n",
      "\u001b[0;32m      4\u001b[0m   layers\u001b[38;5;241m.\u001b[39mRandomFlip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal_and_vertical\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n",
      "\u001b[0;32m      5\u001b[0m   layers\u001b[38;5;241m.\u001b[39mRandomRotation(\u001b[38;5;241m0.2\u001b[39m),\n",
      "\u001b[0;32m      6\u001b[0m ])\n",
      "\u001b[1;32m----> 8\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m      9\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: (data_augmentation(x), y))\n",
      "\u001b[0;32m     10\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: (data_augmentation(x), y))\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2202\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n",
      "\u001b[0;32m   2199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n",
      "\u001b[0;32m   2200\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   2201\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m-> 2202\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   2203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m   2204\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n",
      "\u001b[0;32m   2205\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[0;32m   2206\u001b[0m       map_func,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   2209\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[0;32m   2210\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5400\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n",
      "\u001b[0;32m   5398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n",
      "\u001b[0;32m   5399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n",
      "\u001b[1;32m-> 5400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   5401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   5402\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   5403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   5404\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   5405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n",
      "\u001b[0;32m   5406\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n",
      "\u001b[0;32m   5407\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;32m   5408\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   5411\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n",
      "\u001b[0;32m   5412\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n",
      "\u001b[0;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n",
      "\u001b[0;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n",
      "\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n",
      "\u001b[0;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[0;32m   2602\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n",
      "\u001b[0;32m   2603\u001b[0m \n",
      "\u001b[0;32m   2604\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   2608\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n",
      "\u001b[0;32m   2609\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n",
      "\u001b[0;32m   2611\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   2612\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;32m   2613\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   2577\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;32m   2578\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n",
      "\u001b[0;32m   2579\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n",
      "\u001b[0;32m   2758\u001b[0m   \u001b[38;5;66;03m# Only get placeholders for arguments, not captures\u001b[39;00m\n",
      "\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m placeholder_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_capture_func_lib  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# Maintain the list of all captures\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n",
      "\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[0;32m   2666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n",
      "\u001b[0;32m   2667\u001b[0m ]\n",
      "\u001b[0;32m   2668\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n",
      "\u001b[0;32m   2669\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n",
      "\u001b[1;32m-> 2670\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n",
      "\u001b[0;32m   2680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n",
      "\u001b[0;32m   2681\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n",
      "\u001b[0;32m   2682\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n",
      "\u001b[0;32m   2683\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n",
      "\u001b[0;32m   2684\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n",
      "\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n",
      "\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n",
      "\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n",
      "\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n",
      "\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n",
      "\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n",
      "\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n",
      "\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n",
      "\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n",
      "\u001b[0;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n",
      "\u001b[0;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n",
      "\u001b[0;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[0;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n",
      "\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n",
      "\u001b[1;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n",
      "\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n",
      "\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n",
      "\u001b[0;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n",
      "\u001b[1;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "\u001b[0;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n",
      "\u001b[0;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n",
      "\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n",
      "\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file00m_d4dt.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(x, y)\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n",
      "\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_function_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlscope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTD\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[1;34m(thunk, scope_name, options)\u001b[0m\n",
      "\u001b[0;32m    111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_\u001b[39m\u001b[38;5;124m'\u001b[39m, scope_name, options) \u001b[38;5;28;01mas\u001b[39;00m scope:\n",
      "\u001b[1;32m--> 113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file00m_d4dt.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(lscope)\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n",
      "\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: ag__\u001b[38;5;241m.\u001b[39mwith_function_scope(\u001b[38;5;28;01mlambda\u001b[39;00m lscope: (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m, y), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD)\n",
      "\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n",
      "\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n",
      "\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n",
      "\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n",
      "\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n",
      "\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n",
      "\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n",
      "\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n",
      "\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n",
      "\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n",
      "\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\preprocessing\\image_preprocessing.py:444\u001b[0m, in \u001b[0;36mBaseImageAugmentationLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n",
      "\u001b[0;32m    440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_output(\n",
      "\u001b[0;32m    441\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_augment(inputs), is_dict, use_targets\n",
      "\u001b[0;32m    442\u001b[0m         )\n",
      "\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    445\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage augmentation layers are expecting inputs to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    446\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank 3 (HWC) or 4D (NHWC) tensors. Got shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    447\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    448\u001b[0m         )\n",
      "\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n",
      "\n",
      "    File \"C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_39772\\3991776876.py\", line 8, in None  *\n",
      "        lambda x, y: (data_augmentation(x), y)\n",
      "    File \"c:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"c:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\preprocessing\\image_preprocessing.py\", line 444, in call\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: Exception encountered when calling layer \"random_flip_2\" \"                 f\"(type RandomFlip).\n",
      "    \n",
      "    Image augmentation layers are expecting inputs to be rank 3 (HWC) or 4D (NHWC) tensors. Got shape: (None, None, 56, 56, 1)\n",
      "    \n",
      "    Call arguments received by layer \"random_flip_2\" \"                 f\"(type RandomFlip):\n",
      "      • inputs=tf.Tensor(shape=(None, None, 56, 56, 1), dtype=float32)\n",
      "      • training=True\n"
     ]
    }
   ],
   "source": [
    "print(\"starting augmentation\")\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01345a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 80)        800       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 80)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 25, 25, 160)       115360    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 160)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 320)       461120    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 320)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 3, 640)         1843840   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 640)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 640)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              656384    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               205000    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7330)              1473330   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,755,834\n",
      "Trainable params: 4,755,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "80577/80577 [==============================] - 923s 11ms/step - loss: 4.5368 - accuracy: 0.1901 - val_loss: 3.9787 - val_accuracy: 0.2023\n",
      "Epoch 2/10\n",
      "80577/80577 [==============================] - 954s 12ms/step - loss: 2.1836 - accuracy: 0.4889 - val_loss: 3.0539 - val_accuracy: 0.3417\n",
      "Epoch 3/10\n",
      "80577/80577 [==============================] - 971s 12ms/step - loss: 1.7578 - accuracy: 0.5776 - val_loss: 2.8607 - val_accuracy: 0.3728\n",
      "Epoch 4/10\n",
      "80577/80577 [==============================] - 1016s 13ms/step - loss: 1.5756 - accuracy: 0.6177 - val_loss: 2.6088 - val_accuracy: 0.4114\n",
      "Epoch 5/10\n",
      "80577/80577 [==============================] - 1038s 13ms/step - loss: 1.4821 - accuracy: 0.6388 - val_loss: 2.4531 - val_accuracy: 0.4443\n",
      "Epoch 6/10\n",
      "80577/80577 [==============================] - 1073s 13ms/step - loss: 1.4271 - accuracy: 0.6516 - val_loss: 2.3378 - val_accuracy: 0.4643\n",
      "Epoch 7/10\n",
      "80577/80577 [==============================] - 1067s 13ms/step - loss: 1.3896 - accuracy: 0.6604 - val_loss: 2.3680 - val_accuracy: 0.4592\n",
      "Epoch 8/10\n",
      "80577/80577 [==============================] - 1075s 13ms/step - loss: 1.3638 - accuracy: 0.6665 - val_loss: 2.3923 - val_accuracy: 0.4564\n",
      "Epoch 9/10\n",
      "80577/80577 [==============================] - 1077s 13ms/step - loss: 1.3438 - accuracy: 0.6713 - val_loss: 2.4997 - val_accuracy: 0.4379\n",
      "Epoch 10/10\n",
      "80577/80577 [==============================] - 1143s 14ms/step - loss: 1.3276 - accuracy: 0.6748 - val_loss: 2.3289 - val_accuracy: 0.4671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21df1f735b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "#model.add(normalization_layer_train)\n",
    "model.add(layers.Conv2D(filters=80, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(56,56,1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters=160, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters=320, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters= 640, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=1024, activation='relu'))\n",
    "model.add(layers.Dense(units=200, activation='relu'))\n",
    "model.add(layers.Dense(units=7330, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3e5a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m predict_img \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124methan\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmandarin_images\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnew_test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfinal_images\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCASIA-HWDB_Test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m中\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m56\u001b[39m,\u001b[38;5;241m56\u001b[39m))\n",
      "\u001b[0;32m      2\u001b[0m img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimg_to_array(predict_img)\n",
      "\u001b[0;32m      3\u001b[0m img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "predict_img = tf.keras.utils.load_img(r\"C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Test\\Test\\中\\1.png\", target_size=(56,56))\n",
    "img_array = tf.keras.utils.img_to_array(predict_img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "img_array = img_array/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4621189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 442ms/step\n",
      "[58]\n"
     ]
    }
   ],
   "source": [
    "# Convert the image to grayscale\n",
    "img_array_gray = tf.image.rgb_to_grayscale(img_array)\n",
    "\n",
    "# Normalize the grayscale image\n",
    "img_array_gray = img_array_gray / 255.0\n",
    "\n",
    "# Predict the class\n",
    "prediction = model.predict(img_array_gray)\n",
    "predicted_class = numpy.argmax(prediction, axis=-1)\n",
    "\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5a75e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} Matrix size-incompatible: In[0]: [100352,1], In[1]: [3,1] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[41], line 9\u001b[0m\n",
      "\u001b[0;32m      7\u001b[0m y_true\u001b[38;5;241m.\u001b[39mappend(label_batch)\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# compute predictions\u001b[39;00m\n",
      "\u001b[1;32m----> 9\u001b[0m label_batch \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrgb_to_grayscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     10\u001b[0m label_batch \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(label_batch, (label_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;32m     11\u001b[0m label_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(label_batch, layers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m.1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m))\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ethan\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n",
      "\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n",
      "\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} Matrix size-incompatible: In[0]: [100352,1], In[1]: [3,1] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in train_dataset:   # use dataset.unbatch() with repeat\n",
    "    # append true labels\n",
    "    y_true.append(label_batch)\n",
    "    # compute predictions\n",
    "    label_batch = tf.image.rgb_to_grayscale(image_batch)\n",
    "    label_batch = tf.reshape(label_batch, (label_batch.shape[0], -1))\n",
    "    label_batch = map(label_batch, layers.Rescaling(.1/255))\n",
    "    preds = model.predict(image_batch)\n",
    "    # append predicted labels\n",
    "    y_pred.append(numpy.argmax(preds, axis = - 1))\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b727aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 56, 56, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7330), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "class_names = train_dataset.element_spec\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eabf579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Train\\Train\\0\\3.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34dbc295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_chinese = os.listdir(train_dir)\\ntest_chinese = os.listdir(test_dir)\\nlen(train_chinese)\\nlen(test_chinese)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = pathlib.Path(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Train\\Train')\n",
    "test_dir = pathlib.Path(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Test\\Test')\n",
    "'''\n",
    "train_chinese = os.listdir(train_dir)\n",
    "test_chinese = os.listdir(test_dir)\n",
    "len(train_chinese)\n",
    "len(test_chinese)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d93e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_contrast(image, label):\n",
    "    # Rescale image values to [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    \n",
    "    # Maximize contrast using tf.image.adjust_contrast\n",
    "    image = tf.image.adjust_contrast(image, contrast_factor=2.0)\n",
    "    \n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9474ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3223042 files belonging to 7330 classes.\n",
      "Using 2578434 files for training.\n",
      "Using 644608 files for validation.\n",
      "Found 776523 files belonging to 7330 classes.\n"
     ]
    }
   ],
   "source": [
    "#make tensorflow dataset from image directory\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    image_size = (56, 56),\n",
    "    shuffle = True,\n",
    "    seed=42,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'both',\n",
    "    interpolation = \"bilinear\",\n",
    "    crop_to_aspect_ratio = False\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    image_size = (56, 56),\n",
    "    shuffle = True,\n",
    "    interpolation = \"bilinear\",\n",
    "    crop_to_aspect_ratio = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a543a4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting rescaling\n"
     ]
    }
   ],
   "source": [
    "#apply max contrast to images\n",
    "\n",
    "train_dataset = train_dataset.map(maximize_contrast)\n",
    "val_dataset = val_dataset.map(maximize_contrast)\n",
    "test_dataset =  test_dataset.map(maximize_contrast)\n",
    "\n",
    "print(\"starting rescaling\")\n",
    "\n",
    "rescaling_layer = layers.Rescaling(scale=1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (rescaling_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95a1241-06a7-4785-9913-42edf21a974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting normalization\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to allocate memory for the batch of component 1 [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 46\u001b[0m\n\u001b[0;32m     41\u001b[0m     overall_variance \u001b[38;5;241m=\u001b[39m variance_accumulator \u001b[38;5;241m/\u001b[39m sample_count\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overall_mean\u001b[38;5;241m.\u001b[39mnumpy(), overall_variance\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 46\u001b[0m train_mean, train_variance \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_mean_variance_incrementally\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m test_mean, test_variance \u001b[38;5;241m=\u001b[39m calculate_mean_variance_incrementally(test_dataset)\n\u001b[0;32m     48\u001b[0m val_mean, val_variance \u001b[38;5;241m=\u001b[39m calculate_mean_variance_incrementally(val_dataset)\n",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m, in \u001b[0;36mcalculate_mean_variance_incrementally\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     19\u001b[0m variance_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     20\u001b[0m sample_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Flatten images to process all pixels\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     flattened_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(images, (images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     25\u001b[0m     batch_size, num_pixels \u001b[38;5;241m=\u001b[39m flattened_images\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3018\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to allocate memory for the batch of component 1 [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"starting normalization\")\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "'''\n",
    "train_dataset_for_adapt = train_dataset.map(lambda x, y: x)\n",
    "test_dataset_for_adapt = test_dataset.map(lambda x, y: x)\n",
    "val_dataset_for_adapt = val_dataset.map(lambda x, y: x)\n",
    "\n",
    "normalization_layer_train = layers.Normalization(axis=-1)\n",
    "normalization_layer_test = layers.Normalization(axis=-1)\n",
    "normalization_layer_val = layers.Normalization(axis=-1)\n",
    "'''\n",
    "\n",
    "def calculate_mean_variance_incrementally(dataset):\n",
    "    # Initialize variables for mean, variance, and sample count\n",
    "    mean_accumulator = 0.0\n",
    "    variance_accumulator = 0.0\n",
    "    sample_count = 0\n",
    "    \n",
    "    for images, _ in dataset:\n",
    "        # Flatten images to process all pixels\n",
    "        flattened_images = tf.reshape(images, (images.shape[0], -1))\n",
    "        batch_size, num_pixels = flattened_images.shape\n",
    "        \n",
    "        # Update total sample count\n",
    "        sample_count += batch_size * num_pixels\n",
    "        \n",
    "        # Calculate batch mean and variance\n",
    "        batch_mean = tf.reduce_mean(flattened_images)\n",
    "        batch_variance = tf.reduce_mean(tf.square(flattened_images - batch_mean))\n",
    "        \n",
    "        # Incrementally update the accumulated mean and variance\n",
    "        delta = batch_mean - mean_accumulator\n",
    "        mean_accumulator += delta / sample_count * (batch_size * num_pixels)\n",
    "        variance_accumulator += batch_variance * (batch_size * num_pixels)\n",
    "    \n",
    "    # Finalize mean and variance calculation\n",
    "    overall_mean = mean_accumulator\n",
    "    overall_variance = variance_accumulator / sample_count\n",
    "    \n",
    "    return overall_mean.numpy(), overall_variance.numpy()\n",
    "\n",
    "\n",
    "train_mean, train_variance = calculate_mean_variance_incrementally(train_dataset)\n",
    "test_mean, test_variance = calculate_mean_variance_incrementally(test_dataset)\n",
    "val_mean, val_variance = calculate_mean_variance_incrementally(val_dataset)\n",
    "\n",
    "normalization_layer_train = layers.Normalization(axis=-1, mean=train_mean, variance=train_variance)\n",
    "normalization_layer_test = layers.Normalization(axis=-1, mean=test_mean, variance=test_variance)\n",
    "normalization_layer_val = layers.Normalization(axis=-1, mean=val_mean, variance=val_variance)\n",
    "\n",
    "'''\n",
    "print(\"starting adapt\")\n",
    "normalization_layer_train.adapt(train_dataset_for_adapt)\n",
    "normalization_layer_test.adapt(test_dataset_for_adapt)\n",
    "normalization_layer_val.adapt(val_dataset_for_adapt)\n",
    "\n",
    "print(\"finished adapt\")\n",
    "\n",
    "'''\n",
    "'''\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer_train(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer_test(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer_val(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a1e05a-e39a-4a44-8ac0-341aade09d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting augmentation\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "print(\"starting augmentation\")\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d765840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 80)        800       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 80)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 25, 25, 160)       115360    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 160)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 320)       461120    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 320)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 3, 640)         1843840   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 640)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 1, 1024)        656384    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 1, 200)         205000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7330)              1473330   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,755,834\n",
      "Trainable params: 4,755,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "80577/80577 [==============================] - 1649s 20ms/step - loss: 6.6036 - accuracy: 0.0296 - val_loss: 10.1558 - val_accuracy: 0.0059\n",
      "Epoch 2/10\n",
      "80577/80577 [==============================] - 1498s 19ms/step - loss: 4.6542 - accuracy: 0.1357 - val_loss: 11.6123 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "80577/80577 [==============================] - 1491s 19ms/step - loss: 3.9563 - accuracy: 0.2161 - val_loss: 12.3480 - val_accuracy: 0.0078\n",
      "Epoch 4/10\n",
      "80577/80577 [==============================] - 1485s 18ms/step - loss: 3.6660 - accuracy: 0.2575 - val_loss: 12.1321 - val_accuracy: 0.0073\n",
      "Epoch 5/10\n",
      "80577/80577 [==============================] - 1490s 18ms/step - loss: 3.5138 - accuracy: 0.2810 - val_loss: 12.4194 - val_accuracy: 0.0079\n",
      "Epoch 6/10\n",
      "80577/80577 [==============================] - 1492s 19ms/step - loss: 3.4067 - accuracy: 0.2978 - val_loss: 12.4819 - val_accuracy: 0.0080\n",
      "Epoch 7/10\n",
      "80577/80577 [==============================] - 1493s 19ms/step - loss: 3.3227 - accuracy: 0.3118 - val_loss: 12.5721 - val_accuracy: 0.0078\n",
      "Epoch 8/10\n",
      "80577/80577 [==============================] - 1495s 19ms/step - loss: 3.2597 - accuracy: 0.3212 - val_loss: 12.8869 - val_accuracy: 0.0073\n",
      "Epoch 9/10\n",
      "80577/80577 [==============================] - 1507s 19ms/step - loss: 3.2156 - accuracy: 0.3290 - val_loss: 12.9002 - val_accuracy: 0.0071\n",
      "Epoch 10/10\n",
      "80577/80577 [==============================] - 1492s 19ms/step - loss: 3.1781 - accuracy: 0.3352 - val_loss: 13.3983 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b9df8a400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "#model.add(normalization_layer_train)\n",
    "model.add(layers.Conv2D(filters = 80, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(56,56,1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters= 160, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters= 320, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters= 640, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dense(units=1024, activation='relu'))\n",
    "model.add(layers.Dense(units=200, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=7330, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387979f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MapDataset' object has no attribute 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_classes)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MapDataset' object has no attribute 'num_classes'"
     ]
    }
   ],
   "source": [
    "num_classes = train_dataset.num_classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e76b2-be5f-40df-ba3e-8a4a7c79409d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
