{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f983d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import os\n",
    "import sys\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ba52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory\n",
    "os.chdir(r'C:\\Users\\ethan\\Desktop\\mandarin_recognition_code2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac5b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_chinese = os.listdir(train_dir)\\ntest_chinese = os.listdir(test_dir)\\nlen(train_chinese)\\nlen(test_chinese)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dir = pathlib.Path(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Train\\Train')\n",
    "test_dir = pathlib.Path(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Test\\Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f558217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3223042 files belonging to 7330 classes.\n",
      "Using 2578434 files for training.\n",
      "Using 644608 files for validation.\n",
      "Found 776523 files belonging to 7330 classes.\n"
     ]
    }
   ],
   "source": [
    "#make tensorflow dataset from image directory (if not already saved on local disk)\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    image_size = (56, 56),\n",
    "    shuffle = True,\n",
    "    seed=42,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'both',\n",
    "    interpolation = \"bilinear\",\n",
    "    crop_to_aspect_ratio = False\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    image_size = (56, 56),\n",
    "    shuffle = True,\n",
    "    interpolation = \"bilinear\",\n",
    "    crop_to_aspect_ratio = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if it is first time generating dataset, save it to local disk\n",
    "tf.data.Dataset.save(train_dataset, 'train_dataset')\n",
    "tf.data.Dataset.save(val_dataset, 'val_dataset')\n",
    "tf.data.Dataset.save(test_dataset, 'test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c416e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset from local disk\n",
    "train_dataset = tf.data.Dataset.load('train_dataset')\n",
    "test_dataset = tf.data.Dataset.load('test_dataset')\n",
    "val_dataset = tf.data.Dataset.load('val_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8e47aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (32, 56, 56, 1)\n",
      "Labels shape: (32, 7330)\n"
     ]
    }
   ],
   "source": [
    "#Check shape of dataset\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972eeea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting rescaling\n"
     ]
    }
   ],
   "source": [
    "print(\"starting rescaling\")\n",
    "\n",
    "rescaling_layer = layers.Rescaling(scale=1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (rescaling_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46fe292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Normalization(axis=None)\n",
    "normalization_layer.adapt(train_dataset.map(lambda x, y: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01345a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  multiple                 3         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 54, 54, 80)        800       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 80)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 25, 160)       115360    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 160)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 320)       461120    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 320)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 640)         1843840   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 640)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 640)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              656384    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               205000    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7330)              1473330   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,755,837\n",
      "Trainable params: 4,755,834\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "80577/80577 [==============================] - 663s 8ms/step - loss: 4.6354 - accuracy: 0.1820 - val_loss: 4.2782 - val_accuracy: 0.1689\n",
      "Epoch 2/10\n",
      "80577/80577 [==============================] - 655s 8ms/step - loss: 2.2573 - accuracy: 0.4754 - val_loss: 3.3643 - val_accuracy: 0.2913\n",
      "Epoch 3/10\n",
      "80577/80577 [==============================] - 656s 8ms/step - loss: 1.8091 - accuracy: 0.5680 - val_loss: 2.7938 - val_accuracy: 0.3771\n",
      "Epoch 4/10\n",
      "80577/80577 [==============================] - 671s 8ms/step - loss: 1.6198 - accuracy: 0.6096 - val_loss: 2.6849 - val_accuracy: 0.4019\n",
      "Epoch 5/10\n",
      "80577/80577 [==============================] - 657s 8ms/step - loss: 1.5161 - accuracy: 0.6327 - val_loss: 2.6156 - val_accuracy: 0.4148\n",
      "Epoch 6/10\n",
      "80577/80577 [==============================] - 660s 8ms/step - loss: 1.4551 - accuracy: 0.6463 - val_loss: 2.5747 - val_accuracy: 0.4275\n",
      "Epoch 7/10\n",
      "80577/80577 [==============================] - 657s 8ms/step - loss: 1.4150 - accuracy: 0.6559 - val_loss: 2.4821 - val_accuracy: 0.4422\n",
      "Epoch 8/10\n",
      "80577/80577 [==============================] - 656s 8ms/step - loss: 1.3887 - accuracy: 0.6621 - val_loss: 2.3063 - val_accuracy: 0.4734\n",
      "Epoch 9/10\n",
      "80577/80577 [==============================] - 655s 8ms/step - loss: 1.3681 - accuracy: 0.6667 - val_loss: 2.4654 - val_accuracy: 0.4453\n",
      "Epoch 10/10\n",
      "80577/80577 [==============================] - 640s 8ms/step - loss: 1.3530 - accuracy: 0.6699 - val_loss: 2.2612 - val_accuracy: 0.4842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14a750c5670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Input(shape=(56, 56, 1)))\n",
    "model.add(normalization_layer)\n",
    "model.add(layers.Conv2D(filters=80, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters=160, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters=320, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters= 640, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=1024, activation='relu'))\n",
    "model.add(layers.Dense(units=200, activation='relu'))\n",
    "model.add(layers.Dense(units=7330, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e233fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mandarin_classification_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mandarin_classification_v1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('mandarin_classification_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7080e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mandarin_classification_v1')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3e5a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m predict_img \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124methan\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmandarin_images\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnew_test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfinal_images\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCASIA-HWDB_Test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m中\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m56\u001b[39m,\u001b[38;5;241m56\u001b[39m))\n",
      "\u001b[0;32m      2\u001b[0m img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimg_to_array(predict_img)\n",
      "\u001b[0;32m      3\u001b[0m img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "predict_img = tf.keras.utils.load_img(r\"C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Test\\Test\\中\\1.png\", target_size=(56,56))\n",
    "img_array = tf.keras.utils.img_to_array(predict_img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "img_array = img_array/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4621189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 442ms/step\n",
      "[58]\n"
     ]
    }
   ],
   "source": [
    "# Convert the image to grayscale\n",
    "img_array_gray = tf.image.rgb_to_grayscale(img_array)\n",
    "\n",
    "# Normalize the grayscale image\n",
    "img_array_gray = img_array_gray / 255.0\n",
    "\n",
    "# Predict the class\n",
    "prediction = model.predict(img_array_gray)\n",
    "predicted_class = numpy.argmax(prediction, axis=-1)\n",
    "\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in train_dataset:   # use dataset.unbatch() with repeat\n",
    "    # append true labels\n",
    "    y_true.append(label_batch)\n",
    "    # compute predictions\n",
    "    label_batch = tf.image.rgb_to_grayscale(image_batch)\n",
    "    label_batch = tf.reshape(label_batch, (label_batch.shape[0], -1))\n",
    "    label_batch = map(label_batch, layers.Rescaling(.1/255))\n",
    "    preds = model.predict(image_batch)\n",
    "    # append predicted labels\n",
    "    y_pred.append(numpy.argmax(preds, axis = - 1))\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b727aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 56, 56, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7330), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "class_names = train_dataset.element_spec\n",
    "print(class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
