{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f983d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import os\n",
    "import sys\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eabf579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Train\\Train\\0\\3.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34dbc295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_chinese = os.listdir(train_dir)\\ntest_chinese = os.listdir(test_dir)\\nlen(train_chinese)\\nlen(test_chinese)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = pathlib.Path(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Train\\Train')\n",
    "test_dir = pathlib.Path(r'C:\\Users\\ethan\\Downloads\\mandarin_images\\new_test\\final_images\\CASIA-HWDB_Test\\Test')\n",
    "'''\n",
    "train_chinese = os.listdir(train_dir)\n",
    "test_chinese = os.listdir(test_dir)\n",
    "len(train_chinese)\n",
    "len(test_chinese)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d93e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_contrast(image, label):\n",
    "    # Rescale image values to [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    \n",
    "    # Maximize contrast using tf.image.adjust_contrast\n",
    "    image = tf.image.adjust_contrast(image, contrast_factor=2.0)\n",
    "    \n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9474ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3223042 files belonging to 7330 classes.\n",
      "Using 2578434 files for training.\n",
      "Using 644608 files for validation.\n",
      "Found 776523 files belonging to 7330 classes.\n"
     ]
    }
   ],
   "source": [
    "#make tensorflow dataset from image directory\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    image_size = (56, 56),\n",
    "    shuffle = True,\n",
    "    seed=42,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'both',\n",
    "    interpolation = \"bilinear\",\n",
    "    crop_to_aspect_ratio = False\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 32,\n",
    "    image_size = (56, 56),\n",
    "    shuffle = True,\n",
    "    interpolation = \"bilinear\",\n",
    "    crop_to_aspect_ratio = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a543a4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting rescaling\n"
     ]
    }
   ],
   "source": [
    "#apply max contrast to images\n",
    "\n",
    "train_dataset = train_dataset.map(maximize_contrast)\n",
    "val_dataset = val_dataset.map(maximize_contrast)\n",
    "test_dataset =  test_dataset.map(maximize_contrast)\n",
    "\n",
    "print(\"starting rescaling\")\n",
    "\n",
    "rescaling_layer = layers.Rescaling(scale=1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (rescaling_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95a1241-06a7-4785-9913-42edf21a974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting normalization\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to allocate memory for the batch of component 1 [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 46\u001b[0m\n\u001b[0;32m     41\u001b[0m     overall_variance \u001b[38;5;241m=\u001b[39m variance_accumulator \u001b[38;5;241m/\u001b[39m sample_count\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overall_mean\u001b[38;5;241m.\u001b[39mnumpy(), overall_variance\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 46\u001b[0m train_mean, train_variance \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_mean_variance_incrementally\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m test_mean, test_variance \u001b[38;5;241m=\u001b[39m calculate_mean_variance_incrementally(test_dataset)\n\u001b[0;32m     48\u001b[0m val_mean, val_variance \u001b[38;5;241m=\u001b[39m calculate_mean_variance_incrementally(val_dataset)\n",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m, in \u001b[0;36mcalculate_mean_variance_incrementally\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     19\u001b[0m variance_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     20\u001b[0m sample_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Flatten images to process all pixels\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     flattened_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(images, (images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     25\u001b[0m     batch_size, num_pixels \u001b[38;5;241m=\u001b[39m flattened_images\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3018\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to allocate memory for the batch of component 1 [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"starting normalization\")\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "'''\n",
    "train_dataset_for_adapt = train_dataset.map(lambda x, y: x)\n",
    "test_dataset_for_adapt = test_dataset.map(lambda x, y: x)\n",
    "val_dataset_for_adapt = val_dataset.map(lambda x, y: x)\n",
    "\n",
    "normalization_layer_train = layers.Normalization(axis=-1)\n",
    "normalization_layer_test = layers.Normalization(axis=-1)\n",
    "normalization_layer_val = layers.Normalization(axis=-1)\n",
    "'''\n",
    "\n",
    "def calculate_mean_variance_incrementally(dataset):\n",
    "    # Initialize variables for mean, variance, and sample count\n",
    "    mean_accumulator = 0.0\n",
    "    variance_accumulator = 0.0\n",
    "    sample_count = 0\n",
    "    \n",
    "    for images, _ in dataset:\n",
    "        # Flatten images to process all pixels\n",
    "        flattened_images = tf.reshape(images, (images.shape[0], -1))\n",
    "        batch_size, num_pixels = flattened_images.shape\n",
    "        \n",
    "        # Update total sample count\n",
    "        sample_count += batch_size * num_pixels\n",
    "        \n",
    "        # Calculate batch mean and variance\n",
    "        batch_mean = tf.reduce_mean(flattened_images)\n",
    "        batch_variance = tf.reduce_mean(tf.square(flattened_images - batch_mean))\n",
    "        \n",
    "        # Incrementally update the accumulated mean and variance\n",
    "        delta = batch_mean - mean_accumulator\n",
    "        mean_accumulator += delta / sample_count * (batch_size * num_pixels)\n",
    "        variance_accumulator += batch_variance * (batch_size * num_pixels)\n",
    "    \n",
    "    # Finalize mean and variance calculation\n",
    "    overall_mean = mean_accumulator\n",
    "    overall_variance = variance_accumulator / sample_count\n",
    "    \n",
    "    return overall_mean.numpy(), overall_variance.numpy()\n",
    "\n",
    "\n",
    "train_mean, train_variance = calculate_mean_variance_incrementally(train_dataset)\n",
    "test_mean, test_variance = calculate_mean_variance_incrementally(test_dataset)\n",
    "val_mean, val_variance = calculate_mean_variance_incrementally(val_dataset)\n",
    "\n",
    "normalization_layer_train = layers.Normalization(axis=-1, mean=train_mean, variance=train_variance)\n",
    "normalization_layer_test = layers.Normalization(axis=-1, mean=test_mean, variance=test_variance)\n",
    "normalization_layer_val = layers.Normalization(axis=-1, mean=val_mean, variance=val_variance)\n",
    "\n",
    "'''\n",
    "print(\"starting adapt\")\n",
    "normalization_layer_train.adapt(train_dataset_for_adapt)\n",
    "normalization_layer_test.adapt(test_dataset_for_adapt)\n",
    "normalization_layer_val.adapt(val_dataset_for_adapt)\n",
    "\n",
    "print(\"finished adapt\")\n",
    "\n",
    "'''\n",
    "'''\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer_train(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer_test(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer_val(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a1e05a-e39a-4a44-8ac0-341aade09d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting augmentation\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "print(\"starting augmentation\")\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d765840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 80)        800       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 80)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 25, 25, 160)       115360    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 160)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 320)       461120    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 320)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 3, 640)         1843840   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 640)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 1, 1024)        656384    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 1, 200)         205000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7330)              1473330   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,755,834\n",
      "Trainable params: 4,755,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "80577/80577 [==============================] - 1649s 20ms/step - loss: 6.6036 - accuracy: 0.0296 - val_loss: 10.1558 - val_accuracy: 0.0059\n",
      "Epoch 2/10\n",
      "80577/80577 [==============================] - 1498s 19ms/step - loss: 4.6542 - accuracy: 0.1357 - val_loss: 11.6123 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "80577/80577 [==============================] - 1491s 19ms/step - loss: 3.9563 - accuracy: 0.2161 - val_loss: 12.3480 - val_accuracy: 0.0078\n",
      "Epoch 4/10\n",
      "80577/80577 [==============================] - 1485s 18ms/step - loss: 3.6660 - accuracy: 0.2575 - val_loss: 12.1321 - val_accuracy: 0.0073\n",
      "Epoch 5/10\n",
      "80577/80577 [==============================] - 1490s 18ms/step - loss: 3.5138 - accuracy: 0.2810 - val_loss: 12.4194 - val_accuracy: 0.0079\n",
      "Epoch 6/10\n",
      "80577/80577 [==============================] - 1492s 19ms/step - loss: 3.4067 - accuracy: 0.2978 - val_loss: 12.4819 - val_accuracy: 0.0080\n",
      "Epoch 7/10\n",
      "80577/80577 [==============================] - 1493s 19ms/step - loss: 3.3227 - accuracy: 0.3118 - val_loss: 12.5721 - val_accuracy: 0.0078\n",
      "Epoch 8/10\n",
      "80577/80577 [==============================] - 1495s 19ms/step - loss: 3.2597 - accuracy: 0.3212 - val_loss: 12.8869 - val_accuracy: 0.0073\n",
      "Epoch 9/10\n",
      "80577/80577 [==============================] - 1507s 19ms/step - loss: 3.2156 - accuracy: 0.3290 - val_loss: 12.9002 - val_accuracy: 0.0071\n",
      "Epoch 10/10\n",
      "80577/80577 [==============================] - 1492s 19ms/step - loss: 3.1781 - accuracy: 0.3352 - val_loss: 13.3983 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b9df8a400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "#model.add(normalization_layer_train)\n",
    "model.add(layers.Conv2D(filters = 80, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(56,56,1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters= 160, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters= 320, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters= 640, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dense(units=1024, activation='relu'))\n",
    "model.add(layers.Dense(units=200, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=7330, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387979f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MapDataset' object has no attribute 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_classes)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MapDataset' object has no attribute 'num_classes'"
     ]
    }
   ],
   "source": [
    "num_classes = train_dataset.num_classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e76b2-be5f-40df-ba3e-8a4a7c79409d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
